{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieLens_Rating_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_UeyGir_6lg",
        "outputId": "e42828c4-d3b1-4891-dc09-d13b16b8c193"
      },
      "source": [
        "pip install keras-rectified-adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-rectified-adam in /usr/local/lib/python3.7/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-rectified-adam) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-rectified-adam) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-rectified-adam) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-rectified-adam) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-rectified-adam) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-rectified-adam) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd0JVqeKa2K2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8a46d8-e63c-4b50-a749-62378aca0782"
      },
      "source": [
        "import keras\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import dot\n",
        "from keras.layers import Flatten, Dense, Input, Embedding\n",
        "from keras.layers import GlobalAveragePooling1D, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras_radam import RAdam\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdYbaEJlWhFB"
      },
      "source": [
        "movie = pd.read_csv('/content/drive/My Drive/MovieLens/movie.csv')\n",
        "rating = pd.read_csv('/content/drive/My Drive/MovieLens/rating.csv')\n",
        "movie = movie.loc[:,[\"movieId\",\"genres\"]]\n",
        "rating = rating.loc[:,[\"userId\",\"movieId\",\"rating\"]]\n",
        "data = pd.merge(rating, movie)\n",
        "\n",
        "n_movies = len(data['movieId'].unique())\n",
        "n_users = len(data['userId'].unique())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNXr7VvLq0yY"
      },
      "source": [
        "data['rating'] = (data['rating']-0.5)/4.5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKLUnQJsGoLW"
      },
      "source": [
        "genres_split = data.genres.str.split('|').tolist()\n",
        "genres_unique = set()\n",
        "for movie_genres in genres_split:\n",
        "    for genre in movie_genres:\n",
        "        genres_unique.add(genre)\n",
        "genres2idx = {o:i+1 for i,o in enumerate(genres_unique)}\n",
        "genres_split = [[genres2idx[x] for x in movie_genres] for movie_genres in genres_split]\n",
        "padded_genres = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    genres_split, padding=\"post\"\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYMOrCmXmogD",
        "outputId": "ff001e74-20d3-4825-887a-2095457b7e48"
      },
      "source": [
        "n_user_embedding = 32\n",
        "n_movie_embedding = 16\n",
        "n_genres_embedding = 16\n",
        "n_hidden_layer = 32\n",
        "dropout_rate = 0.25\n",
        "\n",
        "user_input = Input(shape=(1,), name='user_input', dtype='int64')\n",
        "user_embedding = Embedding(n_users, n_user_embedding, name='user_embedding')(user_input)\n",
        "user_vector = BatchNormalization()(Dropout(dropout_rate)(Flatten()(user_embedding)))\n",
        "\n",
        "movie_input = Input(shape=(1,), name='movie_input', dtype='int64')\n",
        "movie_embedding = Embedding(n_movies, n_movie_embedding, name='movie_embedding')(movie_input)\n",
        "movie_vector = BatchNormalization()(Dropout(dropout_rate)(Flatten()(movie_embedding)))\n",
        "\n",
        "genres_input = Input(shape=(len(padded_genres[0]),), name='genres_input', dtype='int64') # input = (10, 1)\n",
        "genres_embedding = Embedding(len(genres_unique)+1, n_genres_embedding, mask_zero=True, name='genres_embedding')(genres_input) # input = 21\n",
        "genres_average_embedding = GlobalAveragePooling1D()(genres_embedding)\n",
        "genres_vector = BatchNormalization()(Dropout(dropout_rate)(Flatten()(genres_average_embedding)))\n",
        "\n",
        "concat_layer = tf.concat([user_vector, movie_vector, genres_vector], 1, name='concat_layer')\n",
        "hidden_layer = Dense(n_hidden_layer, activation='relu')(concat_layer)\n",
        "output = Dense(1, activation='sigmoid')(hidden_layer)\n",
        "\n",
        "model = Model([user_input, movie_input, genres_input], output)\n",
        "# age 추가 실험?\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "genres_input (InputLayer)       [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "movie_input (InputLayer)        [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "genres_embedding (Embedding)    (None, 10, 16)       336         genres_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 32)        4431776     user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "movie_embedding (Embedding)     (None, 1, 16)        427904      movie_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 16)           0           genres_embedding[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32)           0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 16)           0           movie_embedding[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 16)           0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32)           0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16)           0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 16)           0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32)           128         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16)           64          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16)           64          dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, 64)           0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           2080        tf.concat[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,862,385\n",
            "Trainable params: 4,862,257\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZR6iLC483BY"
      },
      "source": [
        "users = data.userId.unique()\n",
        "movies = data.movieId.unique()\n",
        "\n",
        "userid2idx = {o:i for i,o in enumerate(users)}\n",
        "movieid2idx = {o:i for i,o in enumerate(movies)}\n",
        "\n",
        "data['userId'] = data['userId'].apply(lambda x: userid2idx[x])\n",
        "data['movieId'] = data['movieId'].apply(lambda x: movieid2idx[x])\n",
        "\n",
        "data = data.drop(columns=['genres'])\n",
        "for i in range(10):\n",
        "    data['genre'+str(i)] = padded_genres[:,i]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwXrljxs659n"
      },
      "source": [
        "split = np.random.rand(len(data)) < 0.9\n",
        "train = data[split]\n",
        "valid = data[~split]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8iU8TEhCXhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3897e4d-be94-446e-9264-f243b4d54fe2"
      },
      "source": [
        "model.compile(optimizer=RAdam(), loss='mse')\n",
        "batch_size=32768\n",
        "epochs=50\n",
        "history = model.fit([train.userId, train.movieId, train.iloc[:,3:13]],train.rating,\n",
        "                    batch_size=batch_size, epochs=epochs,\n",
        "                    validation_data = ([valid.userId, valid.movieId, valid.iloc[:,3:13]],valid.rating), verbose = 1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "550/550 [==============================] - 112s 170ms/step - loss: 0.0817 - val_loss: 0.0442\n",
            "Epoch 2/50\n",
            "550/550 [==============================] - 92s 168ms/step - loss: 0.0408 - val_loss: 0.0373\n",
            "Epoch 3/50\n",
            "550/550 [==============================] - 93s 170ms/step - loss: 0.0379 - val_loss: 0.0358\n",
            "Epoch 4/50\n",
            "550/550 [==============================] - 93s 170ms/step - loss: 0.0363 - val_loss: 0.0349\n",
            "Epoch 5/50\n",
            "550/550 [==============================] - 93s 168ms/step - loss: 0.0353 - val_loss: 0.0342\n",
            "Epoch 6/50\n",
            "550/550 [==============================] - 93s 169ms/step - loss: 0.0345 - val_loss: 0.0337\n",
            "Epoch 7/50\n",
            "550/550 [==============================] - 92s 168ms/step - loss: 0.0338 - val_loss: 0.0332\n",
            "Epoch 8/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0332 - val_loss: 0.0328\n",
            "Epoch 9/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0327 - val_loss: 0.0325\n",
            "Epoch 10/50\n",
            "550/550 [==============================] - 91s 166ms/step - loss: 0.0323 - val_loss: 0.0323\n",
            "Epoch 11/50\n",
            "550/550 [==============================] - 93s 169ms/step - loss: 0.0320 - val_loss: 0.0321\n",
            "Epoch 12/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0316 - val_loss: 0.0319\n",
            "Epoch 13/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0314 - val_loss: 0.0319\n",
            "Epoch 14/50\n",
            "550/550 [==============================] - 93s 168ms/step - loss: 0.0312 - val_loss: 0.0317\n",
            "Epoch 15/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0310 - val_loss: 0.0316\n",
            "Epoch 16/50\n",
            "550/550 [==============================] - 92s 168ms/step - loss: 0.0308 - val_loss: 0.0315\n",
            "Epoch 17/50\n",
            "550/550 [==============================] - 93s 169ms/step - loss: 0.0306 - val_loss: 0.0315\n",
            "Epoch 18/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0305 - val_loss: 0.0315\n",
            "Epoch 19/50\n",
            "550/550 [==============================] - 93s 170ms/step - loss: 0.0304 - val_loss: 0.0314\n",
            "Epoch 20/50\n",
            "550/550 [==============================] - 93s 168ms/step - loss: 0.0302 - val_loss: 0.0314\n",
            "Epoch 21/50\n",
            "550/550 [==============================] - 92s 167ms/step - loss: 0.0301 - val_loss: 0.0313\n",
            "Epoch 22/50\n",
            "550/550 [==============================] - 93s 170ms/step - loss: 0.0300 - val_loss: 0.0313\n",
            "Epoch 23/50\n",
            "550/550 [==============================] - 93s 169ms/step - loss: 0.0299 - val_loss: 0.0313\n",
            "Epoch 24/50\n",
            "550/550 [==============================] - 93s 170ms/step - loss: 0.0298 - val_loss: 0.0312\n",
            "Epoch 25/50\n",
            "550/550 [==============================] - 93s 169ms/step - loss: 0.0297 - val_loss: 0.0312\n",
            "Epoch 26/50\n",
            "465/550 [========================>.....] - ETA: 13s - loss: 0.0297"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-75018c393542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m history = model.fit([train.userId, train.movieId, train.iloc[:,3:13]],train.rating,\n\u001b[1;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_data = ([valid.userId, valid.movieId, valid.iloc[:,3:13]],valid.rating), verbose = 1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}