{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieLens10M_RMSE_7801.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd0JVqeKa2K2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5fa0ef-5c97-4532-fb83-5d5550cc9f53"
      },
      "source": [
        "import keras\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.layers import Flatten, Dense, Input, Embedding, Dot\n",
        "from keras.layers import GlobalAveragePooling1D, MaxPooling1D, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        " \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLiUf7ck0-fh"
      },
      "source": [
        "# load data\n",
        "movie = [i.strip().split(\"::\") for i in open(\"/content/drive/My Drive/MovieLens10M/movies.dat\").readlines()]\n",
        "movie = pd.DataFrame(movie)\n",
        "movie = movie.rename(columns={0: \"movieId\", 1: \"title\"})\n",
        "rating = [i.strip().split(\"::\") for i in open(\"/content/drive/My Drive/MovieLens10M/ratings.dat\").readlines()]\n",
        "rating = pd.DataFrame(rating)\n",
        "rating = rating.rename(columns={0: \"userId\", 1: \"movieId\", 2: \"rating\", 3: \"timestamp\"})\n",
        "movie = movie.loc[:,[\"movieId\"]]\n",
        "rating = rating.loc[:,[\"userId\",\"movieId\",\"rating\",\"timestamp\"]]\n",
        "data = pd.merge(rating, movie)\n",
        "data['rating'] = pd.to_numeric(data['rating'])\n",
        "data['timestamp'] = pd.to_numeric(data['timestamp'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKLUnQJsGoLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fc4c41-b312-46a8-9d7a-93434f489ca6"
      },
      "source": [
        "# preprocessing\n",
        "n_movies = len(data['movieId'].unique())\n",
        "n_users = len(data['userId'].unique())\n",
        "users = data.userId.unique()\n",
        "movies = data.movieId.unique()\n",
        "\n",
        "userid2idx = {o:i for i,o in enumerate(users)}\n",
        "movieid2idx = {o:i for i,o in enumerate(movies)}\n",
        "\n",
        "data['userId'] = data['userId'].apply(lambda x: userid2idx[x])\n",
        "data['movieId'] = data['movieId'].apply(lambda x: movieid2idx[x])\n",
        "\n",
        "min_timestamp = pd.DataFrame(data.loc[:,[\"movieId\",\"timestamp\"]].groupby(['movieId'], as_index=False).min())\n",
        "min_timestamp = min_timestamp.sort_values(by=[\"movieId\"], axis=0)\n",
        "min_timestamp = min_timestamp.rename(columns={\"timestamp\": \"min_timestamp\"})\n",
        "data = pd.merge(data, min_timestamp)\n",
        "data['timestamp'] = data['timestamp'] - data['min_timestamp']\n",
        "data['timestamp'] = data['timestamp'] / (60 * 60 * 24 * 365)\n",
        "data = data.drop(columns=['min_timestamp'])\n",
        "data['day'] = data['timestamp'] * 365 / (7 * 2)\n",
        "data['day'] = data['day'].apply(lambda x: int(x))\n",
        "days = data.day.unique()\n",
        "n_days = len(days)\n",
        "day2idx = {o:i for i,o in enumerate(days)}\n",
        "data['day'] = data['day'].apply(lambda x: day2idx[x])\n",
        "print(n_movies, n_users, len(rating), n_days)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10677 69878 10000054 365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "p6Ci3Ug95l5U",
        "outputId": "a02a20ff-3ef3-4185-d9fb-590a28e03489"
      },
      "source": [
        "# split train and test data\n",
        "data = data.sample(frac=1)\n",
        "split = np.random.rand(len(data)) < 0.9\n",
        "train = data[split]\n",
        "valid = data[~split]\n",
        "data.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5844181</th>\n",
              "      <td>21147</td>\n",
              "      <td>1281</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.448547</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3068810</th>\n",
              "      <td>27656</td>\n",
              "      <td>391</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.270777</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9935425</th>\n",
              "      <td>5700</td>\n",
              "      <td>8018</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.421692</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4604077</th>\n",
              "      <td>47481</td>\n",
              "      <td>793</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.264438</td>\n",
              "      <td>320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4287693</th>\n",
              "      <td>37495</td>\n",
              "      <td>660</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.602982</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4518945</th>\n",
              "      <td>42210</td>\n",
              "      <td>747</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.098289</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7376692</th>\n",
              "      <td>40922</td>\n",
              "      <td>1864</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.005287</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8757954</th>\n",
              "      <td>22659</td>\n",
              "      <td>3070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.962078</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6684553</th>\n",
              "      <td>12382</td>\n",
              "      <td>1502</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.771925</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6898703</th>\n",
              "      <td>25395</td>\n",
              "      <td>1599</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.148910</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         userId  movieId  rating  timestamp  day\n",
              "5844181   21147     1281     5.0   0.448547   28\n",
              "3068810   27656      391     2.0   2.270777  214\n",
              "9935425    5700     8018     3.0   0.421692   80\n",
              "4604077   47481      793     4.5   3.264438  320\n",
              "4287693   37495      660     3.5   3.602982   27\n",
              "4518945   42210      747     3.0   0.098289   25\n",
              "7376692   40922     1864     3.0   0.005287  147\n",
              "8757954   22659     3070     1.0   3.962078   45\n",
              "6684553   12382     1502     1.0   8.771925  122\n",
              "6898703   25395     1599     1.0   5.148910  144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYMOrCmXmogD",
        "outputId": "67e09e97-7ddc-4220-8327-8988e52de726"
      },
      "source": [
        "# generate model\n",
        "embedding_l2 = 1e-6 * 1                                  # regularization\n",
        "dense_l2 = 1e-3 * 1                                      # regularization\n",
        "keras.backend.clear_session()\n",
        "\n",
        "embedding_l2 /= 2\n",
        "dense_l2 /= 2\n",
        "user_input = Input(shape=(1,), name='user_input', dtype='int32')\n",
        "movie_input = Input(shape=(1,), name='movie_input', dtype='int32')\n",
        "day_input = Input(shape=(1,), name='day_input', dtype='int32')\n",
        "time_input = Input(shape=(1,), name='time_input', dtype='float32')\n",
        "time_root = tf.math.sqrt(time_input + 1.0)\n",
        "time_square = tf.math.square(time_input)\n",
        "time_vector = tf.concat([time_input, time_root, time_square], 1)\n",
        "\n",
        "def create_model(n_user_embedding):\n",
        "    n_movie_embedding = n_user_embedding\n",
        "\n",
        "    user_embedding = Embedding(n_users, n_user_embedding, embeddings_regularizer=regularizers.l2(embedding_l2))(user_input)\n",
        "    user_vector = Flatten()(user_embedding)\n",
        "    movie_embedding = Embedding(n_movies, n_movie_embedding, embeddings_regularizer=regularizers.l2(embedding_l2))(movie_input)\n",
        "    movie_vector = Flatten()(movie_embedding)\n",
        "    day_embedding = Embedding(n_days, int(n_user_embedding/8), embeddings_regularizer=regularizers.l2(embedding_l2))(day_input)\n",
        "    day_vector = Flatten()(day_embedding)\n",
        "\n",
        "    concat_layer = tf.concat([user_vector, movie_vector, time_vector, day_vector], 1)\n",
        "    mlp_output = Dense(int(n_user_embedding/2), activation='relu', kernel_regularizer=regularizers.l2(dense_l2))(concat_layer)\n",
        "\n",
        "    user_embedding2 = Embedding(n_users, n_user_embedding, embeddings_regularizer=regularizers.l2(embedding_l2))(user_input)\n",
        "    user_vector2 = Flatten()(user_embedding2)\n",
        "    movie_embedding2 = Embedding(n_movies, n_movie_embedding, embeddings_regularizer=regularizers.l2(embedding_l2))(movie_input)\n",
        "    movie_vector2 = Flatten()(movie_embedding2)\n",
        "    MF = Dot(axes=1)([user_vector2, movie_vector2])\n",
        "\n",
        "    user_embedding3 = Embedding(n_users, n_user_embedding, embeddings_regularizer=regularizers.l2(embedding_l2))(user_input)\n",
        "    user_vector3 = Flatten()(user_embedding3)\n",
        "    movie_embedding3 = Embedding(n_movies, n_movie_embedding, embeddings_regularizer=regularizers.l2(embedding_l2))(movie_input)\n",
        "    movie_vector3 = Flatten()(movie_embedding3)\n",
        "    diff = tf.math.subtract(user_vector3, movie_vector3)\n",
        "    W = tf.Variable(tf.random.normal(shape=[n_user_embedding, 1], stddev=0.1))\n",
        "    MF2 = tf.linalg.matmul(diff, W)\n",
        "\n",
        "    output_layer = tf.concat([mlp_output, MF, MF2], 1)\n",
        "    return output_layer\n",
        "\n",
        "output_layer = tf.concat([create_model(16*x) for x in range(1,9)], 1)\n",
        "output = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(dense_l2))(output_layer)\n",
        "output = output*5.5\n",
        "\n",
        "model = Model([user_input, movie_input, time_input, day_input], output)\n",
        "#model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(16, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(32, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(48, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(64, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(80, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(96, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(112, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.linalg.matmul_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(128, 1) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5kIoxDAk6hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e182a213-c462-46ba-c9e2-02d7d708e077"
      },
      "source": [
        "# training\n",
        "def rmse (y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        " \n",
        "model.compile(optimizer=Adam(1e-4), loss='mse', metrics=[rmse])\n",
        "batch_size = 4096*8\n",
        "epochs = 128\n",
        " \n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_rmse', patience=1, restore_best_weights=True)\n",
        "history = model.fit([train.userId, train.movieId, train.timestamp, train.day], train.rating,\n",
        "                batch_size=batch_size, epochs=epochs, callbacks=[callback],\n",
        "                validation_data = ([valid.userId, valid.movieId, valid.timestamp, valid.day], valid.rating), verbose = 1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/128\n",
            "275/275 [==============================] - 576s 2s/step - loss: 1.5037 - rmse: 1.1000 - val_loss: 1.0137 - val_rmse: 0.8859\n",
            "Epoch 2/128\n",
            "275/275 [==============================] - 550s 2s/step - loss: 0.9752 - rmse: 0.8734 - val_loss: 0.9156 - val_rmse: 0.8655\n",
            "Epoch 3/128\n",
            "275/275 [==============================] - 552s 2s/step - loss: 0.8888 - rmse: 0.8572 - val_loss: 0.8633 - val_rmse: 0.8614\n",
            "Epoch 4/128\n",
            "275/275 [==============================] - 551s 2s/step - loss: 0.8413 - rmse: 0.8535 - val_loss: 0.8313 - val_rmse: 0.8601\n",
            "Epoch 5/128\n",
            "275/275 [==============================] - 552s 2s/step - loss: 0.8100 - rmse: 0.8509 - val_loss: 0.8110 - val_rmse: 0.8596\n",
            "Epoch 6/128\n",
            "275/275 [==============================] - 548s 2s/step - loss: 0.7895 - rmse: 0.8491 - val_loss: 0.7957 - val_rmse: 0.8579\n",
            "Epoch 7/128\n",
            "275/275 [==============================] - 546s 2s/step - loss: 0.7746 - rmse: 0.8468 - val_loss: 0.7854 - val_rmse: 0.8564\n",
            "Epoch 8/128\n",
            "275/275 [==============================] - 556s 2s/step - loss: 0.7601 - rmse: 0.8424 - val_loss: 0.7750 - val_rmse: 0.8531\n",
            "Epoch 9/128\n",
            "275/275 [==============================] - 547s 2s/step - loss: 0.7438 - rmse: 0.8351 - val_loss: 0.7611 - val_rmse: 0.8464\n",
            "Epoch 10/128\n",
            "275/275 [==============================] - 545s 2s/step - loss: 0.7219 - rmse: 0.8232 - val_loss: 0.7450 - val_rmse: 0.8375\n",
            "Epoch 11/128\n",
            "275/275 [==============================] - 546s 2s/step - loss: 0.6957 - rmse: 0.8076 - val_loss: 0.7302 - val_rmse: 0.8287\n",
            "Epoch 12/128\n",
            "275/275 [==============================] - 546s 2s/step - loss: 0.6684 - rmse: 0.7905 - val_loss: 0.7169 - val_rmse: 0.8204\n",
            "Epoch 13/128\n",
            "275/275 [==============================] - 546s 2s/step - loss: 0.6426 - rmse: 0.7738 - val_loss: 0.7062 - val_rmse: 0.8135\n",
            "Epoch 14/128\n",
            "275/275 [==============================] - 545s 2s/step - loss: 0.6165 - rmse: 0.7563 - val_loss: 0.6973 - val_rmse: 0.8075\n",
            "Epoch 15/128\n",
            "275/275 [==============================] - 550s 2s/step - loss: 0.5926 - rmse: 0.7398 - val_loss: 0.6894 - val_rmse: 0.8020\n",
            "Epoch 16/128\n",
            "275/275 [==============================] - 549s 2s/step - loss: 0.5684 - rmse: 0.7225 - val_loss: 0.6840 - val_rmse: 0.7980\n",
            "Epoch 17/128\n",
            "275/275 [==============================] - 552s 2s/step - loss: 0.5464 - rmse: 0.7064 - val_loss: 0.6786 - val_rmse: 0.7940\n",
            "Epoch 18/128\n",
            "275/275 [==============================] - 551s 2s/step - loss: 0.5237 - rmse: 0.6895 - val_loss: 0.6745 - val_rmse: 0.7907\n",
            "Epoch 19/128\n",
            "275/275 [==============================] - 545s 2s/step - loss: 0.5015 - rmse: 0.6723 - val_loss: 0.6712 - val_rmse: 0.7879\n",
            "Epoch 20/128\n",
            "275/275 [==============================] - 558s 2s/step - loss: 0.4804 - rmse: 0.6557 - val_loss: 0.6690 - val_rmse: 0.7857\n",
            "Epoch 21/128\n",
            "275/275 [==============================] - 549s 2s/step - loss: 0.4595 - rmse: 0.6386 - val_loss: 0.6671 - val_rmse: 0.7838\n",
            "Epoch 22/128\n",
            "275/275 [==============================] - 545s 2s/step - loss: 0.4400 - rmse: 0.6223 - val_loss: 0.6660 - val_rmse: 0.7824\n",
            "Epoch 23/128\n",
            "275/275 [==============================] - 560s 2s/step - loss: 0.4211 - rmse: 0.6060 - val_loss: 0.6656 - val_rmse: 0.7815\n",
            "Epoch 24/128\n",
            "275/275 [==============================] - 551s 2s/step - loss: 0.4036 - rmse: 0.5905 - val_loss: 0.6654 - val_rmse: 0.7807\n",
            "Epoch 25/128\n",
            "275/275 [==============================] - 552s 2s/step - loss: 0.3864 - rmse: 0.5748 - val_loss: 0.6658 - val_rmse: 0.7803\n",
            "Epoch 26/128\n",
            "275/275 [==============================] - 553s 2s/step - loss: 0.3701 - rmse: 0.5595 - val_loss: 0.6664 - val_rmse: 0.7801\n",
            "Epoch 27/128\n",
            "275/275 [==============================] - 554s 2s/step - loss: 0.3545 - rmse: 0.5446 - val_loss: 0.6677 - val_rmse: 0.7802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0p2p3KBU70k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75b3e58-ccb1-4abe-813a-4a60600a5fed"
      },
      "source": [
        "# check final RMSE\n",
        "valid_pred = model.predict([valid.userId, valid.movieId, valid.timestamp, valid.day], batch_size = batch_size)\n",
        "valid_pred = [max(min(x, 5), 0.5) for x in valid_pred]\n",
        "test_rmse = mean_squared_error(valid.rating, valid_pred, squared=False) # squared=False -> RMSE\n",
        "print(test_rmse)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7801956721661908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}